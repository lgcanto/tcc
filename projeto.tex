\documentclass[grad,numbers]{coppe}
\usepackage{amsmath, amssymb, diagbox}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}

\makelosymbols
\makeloabbreviations

\begin{document}
  \title{Análise de Notícias do Mercado Financeiro Utilizando Processamento de Linguagem Natural e Aprendizado de Máquina Para Decisões de Swing Trade}
  \foreigntitle{Financial Market News Analysis Using Natural Language Processing and Machine Learning for Swing Trade Decisions}
  \author{Lucas}{Gama Canto}
  \advisor{Prof.}{Heraldo Luís}{Silveira de Almeida}{D.Sc.}

  \examiner{Prof.}{[TODO]Nome do Primeiro Examinador Sobrenome}{D.Sc.}
  \examiner{Prof.}{[TODO]Nome do Segundo Examinador Sobrenome}{Ph.D.}
  \examiner{Prof.}{[TODO]Nome do Terceiro Examinador Sobrenome}{D.Sc.}
  
  \department{ECA}
  
  \date{03}{2020}

  \keyword{Aprendizado de Máquina}
  \keyword{Processamento de Linguagem Natural}
  \keyword{Mercado Financeiro}

  \maketitle

  \frontmatter
  
  \makecatalog
  
  \dedication{Ao povo brasileiro, pela total contribuição em minha graduação.}

  \chapter*{Agradecimentos}

	  \paragraph{}Gostaria de agradecer a todas as pessoas e situações que tornaram este momento possível. Em especial, meus pais Benedita e Manoel, pelo suporte e esforço incondicional em apoiar minha decisão de vir estudar engenharia no Rio de Janeiro, aos professores da graduação, que me fizeram evoluir no âmbito acadêmico, profissional e pessoal, em especial ao meu orientador e professor Heraldo, que não mediu esforços para me ajudar neste trabalho, e aos amigos que me apoiaram e participaram do meu processo de graduação.

  \begin{abstract}

	  \paragraph{}Com o objetivo de automatizar análises fundamentalistas de mercado, o uso de tecnologia para processamento de texto vem sendo utilizado constantemente no meio acadêmico\cite{nlp-academics} e profissional\cite{nlp-industry}. De forma a contribuir para este campo em crescimento, este trabalho discorre um estudo acerca da criação de modelos preditivos sobre a valorização ou desvalorização de ações na bolsa de valores do Brasil (B3, antiga Bovespa) a partir de notícias sobre o mercado brasileiro de forma a auxiliar decisões de Swing Trade, ou seja, compra e venda de ações dentro de uma janela de tempo maior que um dia.
	  \paragraph{}Para isto, o presente projeto utiliza o framework PyText, que se baseia em conceitos de Aprendizado de Máquina, Redes Neurais e Processamento de Linguagem Natural de forma a desenvolver modelos preditivos com a tarefa de classificação textual.

  \end{abstract}

  \begin{foreignabstract}

	  \paragraph{}In order to automate fundamental market analysis, the use of text processing technology has been constantly used in academic\cite{nlp-academics} and professional\cite{nlp-industry} means. To contribute to this growing field, this paper discusses a study about the creation of predictive models regarding the valuation or devaluation of shares on the Brazilian stock exchange (B3, former Bovespa) based on news about the Brazilian market in order to assist Swing Trade decisions, that is, buying and selling stocks within a time window longer than one day.
	  \paragraph{}To this end, the present project uses the PyText framework, which is based on Machine Learning, Neural Networks and Natural Language Processing concepts in order to develop predictive models with the task of textual classification.

  \end{foreignabstract}

  \tableofcontents
  \listoffigures
  \listoftables
  \printlosymbols
  \printloabbreviations

  \mainmatter
%  \doublespacing
	\chapter{Introdução}
		
		\section{Tema}
			\paragraph{}O tema deste trabalho se resume no estudo da criação de modelos preditivos de modo que estes possam prever a valorização ou desvalorização de ações da bolsa de valores por meio do processamento de notícias do mercado brasileiro.
			\paragraph{}Deste modo, o problema a ser abordado é a identificação de quando uma notícia pode impactar positivamente ou negativamente a variação de preço de ações de forma automatizada.
			
		\section{Delimitação}
			\paragraph{}Este trabalho se restringe ao processamento de texto em português brasileiro, tendo como foco a predição da variação de preço das ações que fazem parte da bolsa de valores do Brasil, a B3. Pela indisponibilidade de dados sobre notícias brasileiras contendo a informação do horário de lançamento da notícia, o projeto mira em predições dentro de uma janela de tempo maior que um dia, de forma a auxiliar decisões de Swing Trade, isto é, operações de compra e venda de ações numa janela de tempo maior que um dia.
			\paragraph{}Além disso, o estudo se baseia na ferramenta PyText, um framework recentemente desenvolvido pelo Facebook que providencia modelos de processamento de linguagem natural de última geração através de uma interface simples e extensível\cite{pytext-paper}.
		
		\section{Justificativa}
			\paragraph{}Diante do crescente número de investidores na bolsa de valores no Brasil, nota-se uma maior preocupação da população brasileira acerca da busca por independência financeira e fontes alternativas de renda com o intuito de contribuir à economia familiar, previdência, ou mesmo utilizar este método como fonte principal de renda\cite{bovespa-investors-growth}.
			\paragraph{}Ao mesmo tempo, estudos associados à inteligência artificial, aprendizado de máquina e processamento de linguagem natural continuam emergindo no meio acadêmico e auxiliando o meio profissional como nunca antes, incluindo o mercado financeiro\cite{ai-in-financial-growth}.
			\paragraph{}Através destes dois fatores, o presente trabalho busca contribuir para a difusão do estudo e uso de algumas destas tecnologias sobre um assunto que gradualmente se encontra dentro do interesse da população brasileira e que colabora para uma possível instauração de uma cultura de economia e independência financeira no Brasil.
		
		\section{Objetivos}
			\paragraph{}O objetivo geral do presente trabalho é de analisar modelos preditivos associados ao mercado financeiro que possam ser construídos a partir do framework PyText, tendo como objetivos específicos, apresentar: (1) A busca por dados de notícias e do histórico da bolsa de valores; (2) A lógica utilizada para a união destes dados de forma a construir os conjuntos de dados utilizados no treinamento dos modelos; (3) O pré-processamento dos conjuntos de dados; (4) As possíveis configurações do framework utilizado de forma a obter a melhor performance; (5) O detalhamento e a análise dos modelos finais encontrados.
		
		\section{Metodologia}
			\paragraph{}O trabalho teve início a partir da procura por bases de dados de notícias associadas ao mercado brasileiro e escritas em português do Brasil, seguida pela obtenção do histórico das variações de preço dos ativos que compõem o iBovespa. Após isto, o histórico foi filtrado de forma a manter as informações dos 5 ativos mais significativos e das varições destes ativos que ocorreram dentro da mesma janela de tempo das notícias obtidas. Em seguida, estes dados foram unidos de forma a obter 5 conjuntos de dados para cada ativo, cada um levando em consideração uma diferente janela de tempo para indicar a valorização: de 1 a 5 dias.
			\paragraph{}Logo após, houve a etapa de pré-processamento do corpo das notícias de forma a remover possíveis ruídos e facilitar a etapa de treinamento, sem perda de contexto do conteúdo. Com os conjuntos de dados prontos, foram feitos testes no PyText com o objetivo de definir a melhor configuração possível para a natureza dos dados, e assim obter a melhor performance.
			\paragraph{}Por fim, os testes finais de cada modelo gerado foi detalhado e analisado para permitir uma conclusão e avaliação do processo como um todo.

		\section{Descrição}
			\paragraph{}O capítulo 2 apresenta toda a fundamentação teórica utilizada como base para o projeto a partir de uma breve descrição de como a bolsa de valores funciona seguida de explicações sobre Aprendizado de Máquina, Processamento de Linguagem Natural, Redes Neurais e o framework Pytext.
			\paragraph{}No capítulo 3 é detalhado todo o processo executado para obtenção do conjunto de notícias e do histórico da B3, seguido do pré-processamento realizado nestes dois conjuntos e a criação dos conjuntos de dados finais utilizados para o treino, cada um associado a um ativo e uma janela de tempo específica.
			\paragraph{}Os detalhes das configurações utilizadas no PyText e o treinamento em si é especificado no capítulo 4, onde há uma discussão acerca dos parâmetros encontrados para a geração de modelos mais performáticos, além das métricas finais encontradas para cada modelo gerado.
			\paragraph{}Por fim, o capítulo 5 apresenta uma conclusão acerca dos modelos encontrados seguido por sugestões que futuramente podem ser aplicadas para a evolução do tema e uma possível melhora de desempenho dos modelos preditivos.
			\paragraph{}O código desenvolvido para o pré-processamento e geração dos conjuntos de dados e arquivos de configurações do PyText utilizados para a geração dos modelos podem ser encontrados no repositório do github referenciado em \cite{github}.
   
  \chapter{Fundamentação Teórica}
  
  \section{Bolsa de Valores e Ações}
  	\paragraph{}A Bolsa de Valores é um lugar centralizado onde, além de abranger outros tipos de investimento, se negociam ações (também chamados de ativos ou papéis), isto é, parcelas do capital social de empresas de capital aberto. Atualmente a B3 (Brasil, Bolsa, Balcão) é a Bolsa de Valores oficial do Brasil que em 2017 atingiu a 5ª posição das maiores bolsas de mercados de capitais do mundo em valor de mercado, com um patrimônio de US\$ 13 bilhões\cite{b3-patrimonio}.
  	\paragraph{}As ações são negociadas diariamente a partir das ordens de compra e venda emitidas pelas corretoras durante o pregão eletrônico, que na B3, funciona em dias úteis das 10:00 às 17:00.
  	\subsection{Preços de Ações}
  		\paragraph{}O preço de um ativo na Bolsa de Valores pode ser determinado por diversas razões que podem se relacionar entre si, entre essas, pode-se destacar a lei da oferta e demanda, perspectivas de crescimento da empresa associada ao papel e especulação. A previsibilidade acerca de movimentações no mercado de ações normalmente pode ser baseada em Análise Técnica (AT - estudo dos movimentos do mercado baseado em métricas como preço, volume e taxa de juros\cite{analise-tecnica}), Análise Fundamentalista (AF - estudo feito a partir de resultados financeiros e operacionais, indicando a saúde da empresa\cite{analise-fundamentalista}) ou numa junção destes dois conceitos.
  		\paragraph{}A validade da previsibilidade destas movimentações são questionadas por críticas com base na Hipótese do Mercado Eficiente (HME) e seus três níveis definidos em \cite{emh}:
			\begin{itemize}
				\item HME fraca: Afirma que os preços refletem totalmente a informação contida na sequência histórica dos preços. Ou seja, a AT não consegue prever os movimentos futuros pois os preços passadas só podem descrever o presente.
				\item HME semi-forte: Afirma que os preços presentes não só refletem toda a sequência histórica de preços mas também toda informação pública sobre as organizações associadas ao ativo em questão. Neste nível de eficiência, a AF também não seria capaz de prever movimentos futuros, pois toda informação como demonstrativos de resultados ou análises orçamentárias refletiria apenas o preço presente.
				\item HME forte: Neste nível, é afirmado que \textit{toda} informação conhecida sobre as organizações é totalmente refletida pelo preço presente, logo, nem mesmo aqueles com informações privilegiadas podem utilizar isto como ferramenta para prever preços futuros.
			\end{itemize}
 			\begin{figure}[h]
 				\includegraphics[width=13cm]{emh.jpg}
 				\caption{Os três níveis da HME, cada nível adiciona um tipo de informação cujo com o qual não seria possível prever um movimento de preço no mercado\cite{emh-article}.}
 				\label{fig:emh}
 			\end{figure}
 			\paragraph{}Não há uma reposta correta perante a validade da HME. Porém, muitos acadêmicos acreditam, pelo menos, na HME fraca\cite{emh-br}, fazendo com que, em algumas ocasiões, seja preferível a utilização da AF, ou seja, a análise de resultados financeiros, relatórios anuais e notícias divulgadas acerca do mercado financeiro.
 			
		\subsection{Índice de Bolsa de Valores}
			\paragraph{}Com objetivo de parametrizar algumas informações intrínsecas às bolsas, estas disponibilizam diversos índices. O principal índice da B3 é o Ibovespa, que é formado pelos ativos com maior volume negociado na bolsa nos últimos meses e indica, de forma resumida, o desempenho das ações negociadas na B3. Por ser um indicador principal, muitos fundos de investimento baseados no mercado de ações estão atrelados ao Ibovespa, contribuindo para a atratividade destes ativos de maneira geral.
			\begin{table}[h]
				\caption{Os 5 ativos com o maior volume e participação na B3, associados ao Ibovespa\cite{carteira-bovespa}.}
				\label{tab:ibovespa-5bigger}
				\centering
				{\footnotesize
					\begin{tabular}{|c|c|c|c|}
						\hline
						Código & Ação & Qtde. Teórica & Part.(\%)\\
						\hline
						ITUB4 &  Itaú Unibanco & 4.738.562.684 & 9,095 \\
						PETR4 &  Petrobras & 4.520.185.835 & 7,038 \\
						BBDC4 &  Bradesco & 3.873.597.664 & 7,028 \\
						VALE3 &  Vale S.A. & 3.147.743.563 & 8,414 \\
						ABEV3 &  AMBEV & 4.344.066.764 & 4,173 \\
						\hline
				\end{tabular}}
			\end{table}
			 
  \section{Aprendizado de Máquina}
  	\paragraph{}Pode-se definir Aprendizado de Máquina como o campo de estudo de algoritmos com o objetivo de fazer com que computadores possam agir sem serem explicitamente programados para fazer determinada tarefa. São algoritmos que analisam dados e aprendem com eles, gerando um modelo preditivo que pode fornecer uma predição de algo on mundo.
  	\paragraph{}Outra definição dada por Tom M. Mitchell\cite{ml-mitchell} fala que o campo de Aprendizado de Máquina busca responder a pergunta: ``Como podemos construir sistemas de computadores que possam automaticamente melhorar através de experiência e quais são as leis fundamentais que governam todo este processo de aprendizado?''. Outra definição do mesmo autor\cite{ml-mitchell-book} diz que ``Um programa de computador é dito aprender com a experiência E em respeito a uma tarefa T e medida pelo desempenho P se o seu desempenho em T, medido por P, melhora com a experiência E''. Neste conceito, se fosse desejado um programa de computador que aprendesse a classificar e-mails como spam ou não, por exemplo, poderíamos fazer a seguinte associação:
  	\begin{itemize}
  		\item E = A experiência de ver o usuário classificar emails como spam ou não.
			\item T = A tarefa de classificar os emails.
			\item P = O número ou fração de emails corretamente classificados como spam/não spam
  	\end{itemize}
  	\paragraph{}Geralmente, os algoritmos de Aprendizado de Máquina podem ser divididos em dois tipos: Aprendizado Supervisionado e Aprendizado Não Supervisionado.
  	\subsection{Aprendizado Supervisionado}
  		\paragraph{}Neste tipo, o algoritmo é inicialmente servido por uma série de dados rotulados cujo resultado já é conhecido. A ideia e que o algoritmo aprenda a criar uma estratégia para chegar ao resultado baseando-se nesses dados de modelo inicial. O aprendizado supervisionado pode ser dividido em problemas de regressão ou classificação.
  		\subsubsection{Problema de Regressão}
	  		\paragraph{}Neste tipo de problema, os dados de entrada (parâmetros) são mapeados em uma função contínua. Por exemplo, um algoritmo cujo objetivo fosse prever o preço dos imóveis na cidade do Rio de Janeiro baseando-se em dados como área útil, bairro, número de vagas na garagem, etc é considerado como um problema de regressão, pois o resultado final será um número contínuo, neste caso, o preço dos imóveis.
  		\subsubsection{Problema de Classificação}
  			\paragraph{}Neste caso, os parâmetros são mapeados de forma a classificar os dados em categorias distintas. Por exemplo, um algoritmo utilizado para prever se um tumor é benigno ou maligno a partir de dados como o tamanho, rugosidade do tumor e idade do paciente é considerado um problema de classificação, pois o resultado final será a categoria na qual o tumor pertence.
  			\paragraph{}Os problemas de classificação muitas vezes apresentam desbalanceamento de classes no conjunto de dados utilizado para o treinamento do modelo, ou seja, o conjunto de dados pode apresentar poucas amostras de uma determinada classe em relação às outras envolvidas, o que pode ocasionar falhas na predição da classe minoritária.
  			\paragraph{}De forma a corrigir tal problema, existem algumas técnicas que podem ser baseadas em dois conceitos: \textit{Undersampling} e \textit{Oversampling}. A primeira se resume na remoção de amostras das classes majoritárias, e a segunda, no acréscimo de amostras da classe minoritária a partir das amostras já existentes no conjunto, de forma a se obter um conjunto de dados balanceados.
  			\newpage
  			\begin{figure}[h]
  				\centering
  				\includegraphics[width=13cm]{os_and_us.jpg}
  				\caption{Exemplos das estratégias de \textit{Undersampling} e \textit{Oversampling} em um problema de classificação de 2 classes desbalanceadas\cite{os_and_us}.}
  				\label{fig:os_and_us}
  			\end{figure}
  			\paragraph{}Entretanto, estas técnicas podem gerar alguns efeitos negativos, como por exemplo, a demasiada diminuição do conjunto de dados como um todo no \textit{Undersampling}, o que prejudica o aprendizado. No caso do \textit{Oversampling}, pode-se gerar um maior efeito de sobre-ajuste no modelo preditivo, isto é, pela falta de generalização, o modelo consegue prever muito bem amostras do conjunto de dados de treino, mas se mostra ineficaz ao prever dados de teste.
		\subsection{Aprendizado Não Supervisionado}
			\paragraph{}Neste tipo de aprendizado, não existe um conjunto inicial de dados e resultados, ou seja, nos permite abordar problemas onde temos pouca ou nenhuma ideia do que nossos resultados devem aparentar. Um exemplo, seria um algoritmo onde, utilizando uma coleção de 1000 artigos publicados por uma universidade, fizesse um agrupamento desses artigos, baseando-se em diferente variáveis como frequência de palavras semelhantes, número de paginas, etc.
		\subsection{Avaliação de Desempenho}
			\paragraph{}A avaliação de desempenho de um modelo preditivo pode ser realizada através de diversas métricas que são medidas diante de uma previsão do modelo sobre um conjunto de dados de teste, logo, existe uma necessidade em dividir o conjunto de dados inicial em dados de treino e dados de teste.
			\paragraph{}Não existe um modo ideal de dividir o conjunto de dados, o tamanho do conjunto de treino normalmente é maior que o de teste, de modo que este consiga abranger mais generalizações acerca dos parâmetros do modelo. Assim, algumas proporções são mais comumente usadas, como 60/40, 75/25 e 80/20, proporção baseada no Principio de Pareto que afirma que, 80\% das saídas/consequências vem de 20\% das entradas/causas\cite{pareto_principle}. Levando em consideração o escopo de Aprendizado de Máquina, podemos dizer que 20\% pode mapear 80\% do conjunto de dados.
			\paragraph{}Além disso, em modelos mais simples, também existe a possibilidade de utilizar a Validação Cruzada, uma técnica que separa o conjunto de dados em subconjuntos exclusivos e diferentes e alguns destes subconjuntos são utilizados para treino e outros para teste, de forma iterativa. Um dos métodos de validação cruzada mais famosos é o \textit{k-fold}, onde o conjunto de dados é separado em $k$ subconjuntos e o treino é realizado $k$ vezes, cada vez utilizando um subconjunto diferente para teste e o resto para treino\cite{k-fold}. No final, as métricas de avaliação são definidas como a média diante dos $k$ subconjuntos.
			\subsubsection{Métricas}
				\paragraph{}As métricas utilizadas para avaliação dependem do tipo de problema. Por exemplo, em problemas de regressão é comum utilizar o erro quadrático médio\cite{regression-loss}. Nos problemas de classificação, é comum utilizar as seguintes medidas: Acurácia, Precisão, Cobertura e a Medida F1:
				\begin{itemize}
					\item Acurácia: É a medida que define a assertividade do modelo em geral, se resume na porcentagem de acertos dentre todas as previsões feitas no conjunto de teste.
					\begin{equation*}
						A = \frac{\text{Número total de acertos}}{\text{Número total de palpites}}
					\end{equation*}
					\item Precisão: Medida de assertividade referente a uma classe específica. É a porcentagem de acertos dentre todos os palpites de uma classe.
					\begin{equation*}
						P_X = \frac{\text{Número total de acertos da classe X }}{\text{Número total de palpites da classe X}}
					\end{equation*}
					\item Cobertura: Porcentagem de palpites certos dentro do número de amostras de uma classe específica.
					\begin{equation*}
						C_X = \frac{\text{Número total de acertos da classe X }}{\text{Número total de amostras da classe X}}
					\end{equation*}
					\item  Medida F1: Média harmônica entre Precisão e Cobertura.
						\begin{equation*}
						F1_X = 2\frac{P_X C_X}{P_X + C_X}
						\end{equation*}
				\end{itemize}
  
  \section{Processamento de Linguagem Natural}
  	\paragraph{}Processamento de Linguagem Natural (PNL) se resume ao campo de estudo das tecnologias utilizadas para ajudar computadores a entenderem a linguagem natural dos humanos, é também considerado uma subárea da Inteligência Artificial. Pode ser usado em diversas aplicações\cite{simple-nlp}, como por exemplo:
  	\begin{itemize}
  		\item Aplicativos de tradução de idioma, como o Google Translator
  		\item Processamento de palavras, que empregam PNL para a correção gramática
  		\item Resposta de Voz iterativa em call centers, de forma a responder adequadamente conforme a requisição de usuários
  		\item Assistentes pessoais, como OK Google, Siri, Cortana e Alexa
  	\end{itemize}
	  \paragraph{}Geralmente, o PNL abrange um pré-processamento de texto antes deste ser transformado em uma forma inteligível por computadores, de forma a remover ruídos ou facilitar o processamento, e isto pode ocorrer de diversas formas.
	  \subsection{Sintaxe}
	  	\paragraph{}A sintaxe se refere à forma de como as palavras se organizam em uma sentença para que se obtenha sentido gramatical. Estas são algumas técnicas de sintaxe que podem ser utilizadas no pré-processamento de texto:
	  	\begin{itemize}
	  		\item Stemização: É a transformação de palavras flexionadas para sua forma radical. Por exemplo, as palavras ``estudos'', ``estudar'' e ``estudando'' se transformariam apenas em ``estud'', mas a palavra ``tiver" se transformaria em ``tiv'' e ``tenho" se transformaria em ``tenh''.
	  		\item Lematização: Semelhante à Stemização, porém, a palavra é resumida para seu lema, fazendo com que se alcance um nível maior de abstração. Neste caso, tanto a palavra ``tiver'' como ``tenho'' se transformaria no lema  ``ter''.
	  		\item Remoção de \textit{stopwords}: A remoção de ``palavras de parada'', ou seja, palavras como ``a'', ``de'', ``o'', ``da'', ``que'', ``e'', ``do'' é útil pois, na maioria das vezes, não são informações importantes para construção do modelo.
	  	\end{itemize}
  	\paragraph{}Além destas, outra técnicas mais simples são utilizadas, como a transformação de caracteres maiúsculos para minúsculos.
  	\subsection{Representação Vetorial}
  		\paragraph{}Após o pré-processamento, diversas técnicas podem ser utilizadas para a transformação do texto em números.. TODO
  		\subsubsection{\textit{Bag of Words}}
	  		\paragraph{}TODO
  		\subsubsection{Vetores Baseados em Redes Neurais}
  			\paragraph{}TODO
	  	
  \section{Redes Neurais}
  	\paragraph{}TODO
  	\subsection{Rede BilSTM Com Atenção}
	  	\paragraph{}TODO
  	\subsection{Rede CNN}
  		\paragraph{}TODO
  
  \section{PyText}
  	\paragraph{}TODO
  	\subsection{Configuração}
  		\paragraph{}TODO
  	\subsection{Uso}
  		\paragraph{}TODO
  
  \chapter{Obtenção e Pré-processamento de Dados}
  	\paragraph{}TODO
  	\section{Estratégia}
  		\paragraph{}TODO
  	\section{Pré-processamento}
  		\paragraph{}TODO
  
  \chapter{Treinamento}
	  \paragraph{}TODO
	  \section{Configuração}
		  \paragraph{}TODO
  	\section{Rotina de Treinamento}
  		\paragraph{}TODO
 		\section{Análise}
 			\paragraph{}TODO
 			\begin{table}[h]
 				\caption{Acurácia para o caso de 3 classes.}
 				\label{tab:3c_ac_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 57,34 & 57,78 & 58,15 & 57,32 & 58,34 \\
 						2 & 57,63 & 57,82 & X     & 56,67 & 55,43 \\
 						3 & 57,96 & 57,25 & X     & 58,27 & 57,97 \\
 						4 & 58,77 & 60,21 & 57,84 & 58,32 & 59,55 \\
 						5 & 57,57 & 59,93 & 58,41 & 59,42 & 59,20 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Precisão média para o caso de 3 classes.}
 				\label{tab:3c_pr_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 38,39 & 38,54 & 38,85 & 54,86 & 38,91 \\
 						2 & 55,02 & 38,61 & X     & 60,12 & 53,78 \\
 						3 & 49,65 & 38,28 & X     & 38,82 & 38,72 \\
 						4 & 55,64 & 40,01 & 38,56 & 72,04 & 39,70 \\
 						5 & 53,45 & 39,92 & 39,04 & 39,66 & 39,41 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Cobertura média para o caso de 3 classes.}
 				\label{tab:3c_co_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 39,04 & 38,69 & 38,81 & 40,04 & 38,72 \\
 						2 & 39,66 & 38,73 & X     & 40,86 & 39,25 \\
 						3 & 40,27 & 38,26 & X     & 39,08 & 38,78 \\
 						4 & 41,15 & 39,80 & 38,66 & 40,62 & 39,78 \\
 						5 & 41,29 & 39,82 & 39,11 & 39,70 & 39,60 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Medida F1 média para o caso de 3 classes.}
 				\label{tab:3c_f1_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 38,55 & 38,59 & 38,63 & 41,07 & 38,43 \\
 						2 & 40,28 & 38,64 & X     & 42,73 & 40,62 \\
 						3 & 41,39 & 38,13 & X     & 38,94 & 38,64 \\
 						4 & 42,58 & 39,67 & 38,61 & 42,18 & 39,74 \\
 						5 & 42,71 & 39,53 & 38,97 & 39,63 & 39,50 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			
 			\begin{table}[h]
 				\caption{Acurácia para o caso de 2 classes.}
 				\label{tab:2c_ac_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 58,74 & 56,71 & 57,72 & 56,12 & 57,16 \\
 						2 & 56,16 & 57,61 & 57,83 & 56,71 & 57,54 \\
 						3 & 59,46 & 59,25 & 58,25 & 57,48 & 57,07 \\
 						4 & 57,71 & 58,32 & 60,08 & 58,26 & 58,17 \\
 						5 & 58,97 & 60,52 & 59,61 & 59,33 & 59,37 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Precisão média para o caso de 2 classes.}
 				\label{tab:2c_pr_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 58,97 & 56,93 & 57,73 & 56,10 & 57,04 \\
 						2 & 56,16 & 57,62 & 57,91 & 56,79 & 57,58 \\
 						3 & 59,38 & 59,24 & 58,30 & 57,49 & 57,08 \\
 						4 & 57,73 & 58,04 & 60,35 & 58,28 & 58,16 \\
 						5 & 58,43 & 60,62 & 59,61 & 59,25 & 59,31 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Cobertura média para o caso de 2 classes.}
 				\label{tab:2c_co_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 58,97 & 56,80 & 57,67 & 55,99 & 56,82 \\
 						2 & 56,18 & 57,62 & 57,89 & 56,76 & 57,57 \\
 						3 & 58,97 & 59,21 & 58,25 & 57,50 & 57,07 \\
 						4 & 57,76 & 59,28 & 59,78 & 58,30 & 58,16 \\
 						5 & 58,32 & 60,64 & 59,51 & 59,24 & 59,12 \\
 						\hline
 				\end{tabular}}
 			\end{table}
 			\begin{table}[h]
 				\caption{Medida F1 média para o caso de 2 classes.}
 				\label{tab:2c_f1_analysis}
 				\centering
 				{\footnotesize
 					\begin{tabular}{|c|c|c|c|c|c|}
 						\hline
 						\diagbox[linewidth=0.2pt, width=\dimexpr \textwidth/10+2\tabcolsep\relax, height=0.8cm]{Dias}{Ativo}
 						& ABEV3 & BBDC4 & ITUB4 & PETR4 & VALE3\\
 						\hline
 						1 & 58,74 & 56,54 & 57,61 & 55,84 & 56,63 \\
 						2 & 56,12 & 57,61 & 57,82 & 56,68 & 57,53 \\
 						3 & 58,76 & 59,19 & 58,18 & 57,47 & 57,05 \\
 						4 & 57,67 & 57,83 & 59,39 & 58,23 & 58,15 \\
 						5 & 58,33 & 60,52 & 59,45 & 59,25 & 59,03 \\
 						\hline
 				\end{tabular}}
 			\end{table}
  
  \chapter{Considerações Finais}
  	\paragraph{}TODO
  	\section{Conclusão}
  		\paragraph{}TODO
 		\section{Trabalhos Futuros}
 			\paragraph{}TODO

  \backmatter
  \bibliographystyle{coppe-unsrt}
  \bibliography{bibliography}

  \appendix

	\chapter{Rotinas e Arquivos de Configuração}
		\section{Rotina de Pré-processamento e Criação de Conjuntos de Dados}
		\section{Rotina de Criação de Arquivos de Configuração e Execução de Treinamentos}
		\section{Modelo de Arquivo de Configuração}

\end{document}
%% 
%%
%% End of file `example.tex'.
